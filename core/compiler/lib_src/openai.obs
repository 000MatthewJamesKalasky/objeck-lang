use Web.HTTP, Collection, System.IO.Filesystem, Data.JSON;

#~~
Copyright (c) 2024 Randy Hollines
~~#	

#~
Support for OpenAI audio APIs
~#
bundle API.OpenAI.Audio {
	#~
	Transcribes audio into the input language.
	~#
	class Transcription from EndPoint {
		#~
		Transcribes audio into the input language.
		@param name transcription name
		@param content byte stream to translate
		@param model ID of the model to use
		@param token API token
		@return translated text, Nil if unsuccessful
		~#
		function : Translate(name : String, content : Byte[], model : String, token : String) ~ String {
			return Translate(name, content, model, Nil, Nil, -1.0, token)
		}

		#~
		Transcribes audio into the input language.
		@param name transcription name
		@param content byte stream to translate
		@param model ID of the model to use
		@param prompt text to guide the model's style or continue a previous audio segment
		@param response_format format of the transcript output, options: 'json', 'text', 'srt', 'verbose_json', or 'vtt'
		@param temperature sampling temperature, between 0 and 1, higher values make the output more random
		@param token API token
		@return translated text, Nil if unsuccessful
		~#
		function : Translate(name : String, content : Byte[], model : String, prompt : String, response_format : String, temperature : Float, token : String) ~ String {
			encoder := Web.HTTP.Server.MultipartEncoder->New();

			model_headers := Map->New()<String, String>;
			model_headers->Insert("Content-Disposition", "form-data; name=\"model\"");
			model_content := Web.HTTP.Server.MultipartContent->New(model_headers, model->ToByteArray());
			encoder->Add(model_content);

			content_headers := Map->New()<String, String>;
			content_headers->Insert("Content-Disposition", "form-data; name=\"file\"; filename=\"{$name}\"");
			content_headers->Insert("Content-Type", "application/octet-stream");
			multi_content := Web.HTTP.Server.MultipartContent->New(content_headers, content);
			encoder->Add(multi_content);

			if(prompt <> Nil) {
				prompt_headers := Map->New()<String, String>;
				prompt_headers->Insert("Content-Disposition", "form-data; name=\"prompt\"");
				prompt_content := Web.HTTP.Server.MultipartContent->New(prompt_headers, prompt->ToByteArray());
				encoder->Add(prompt_content);
			};

			if(response_format <> Nil) {
				response_format_headers := Map->New()<String, String>;
				response_format_headers->Insert("Content-Disposition", "form-data; name=\"response_format\"");
				response_format_content := Web.HTTP.Server.MultipartContent->New(response_format_headers, response_format->ToByteArray());
				encoder->Add(response_format_content);
			};

			if(temperature >= 0.0 & temperature <= 1.0) {
				temperature_headers := Map->New()<String, String>;
				temperature_headers->Insert("Content-Disposition", "form-data; name=\"temperature\"");
				temperature_content := Web.HTTP.Server.MultipartContent->New(temperature_headers, temperature->ToString()->ToByteArray());
				encoder->Add(temperature_content);
			};

			data := encoder->ToByteArray();

			boundry := encoder->GetBoundary();
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/audio/transcriptions"), data, 
				"multipart/form-data; boundary={$boundry}", headers);

			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				model_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(model_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};
				
				if(model_json->Has("error")) {
					error_str := model_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return model_json->Get("text")->GetString();
			};

			return Nil;
		}
	}

	#~
	Audio APIs provides two speech to text endpoints, transcriptions and translations
	~#
	class Speech from EndPoint {
		#~
		Generates audio from the input text
		@param model available TTS models 'tts-1' or 'tts-1-hd'
		@param input the text to generate audio for, the maximum length is 4096 characters
		@param voice voice to use when generating the audio, supported voices are alloy, 'echo', 'fable', 'onyx', 'nova', and 'shimmer'. 
		@param token API token
		@return response with type and content, Nil if unsuccessful
		~#
		function : Speak(model : String, input : String, voice : String, token : String) ~ Pair<String, ByteArrayRef> {
			return Speak(model, input, voice, "mp3", 0.0, token);
		}

		#~
		Generates audio from the input text
		@param model available TTS models 'tts-1' or 'tts-1-hd'
		@param input the text to generate audio for, the maximum length is 4096 characters
		@param voice voice to use when generating the audio. Supported voices are alloy, 'echo', 'fable', 'onyx', 'nova', and 'shimmer'. 
		@param response_format format to audio in, supported formats are 'mp3', 'opus', 'aac', 'flac', 'wav', and 'pcm'.
		@param token API token
		@return response with type and content, Nil if unsuccessful
		~#
		function : Speak(model : String, input : String, voice : String, response_format : String, token : String) ~ Pair<String, ByteArrayRef> {
			return Speak(model, input, voice, response_format, 0.0, token);
		}

		#~
		Generates audio from the input text
		@param model available TTS models 'tts-1' or 'tts-1-hd'
		@param input the text to generate audio for, the maximum length is 4096 characters
		@param voice voice to use when generating the audio. Supported voices are alloy, 'echo', 'fable', 'onyx', 'nova', and 'shimmer'. 
		@param speed speed of the generated audio 0.25 to 4.0. 1.0 is the default.
		@param response_format format to audio in, supported formats are 'mp3', 'opus', 'aac', 'flac', 'wav', and 'pcm'.
		@param token API token
		@return response with type and content, Nil if unsuccessful
		~#
		function : Speak(model : String, input : String, voice : String, response_format : String, speed : Float, token : String) ~ Pair<String, ByteArrayRef> {
			audio_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			audio_json->Insert("model", model);
			audio_json->Insert("input", input);
			audio_json->Insert("voice", voice);

			if(response_format <> Nil) {
				audio_json->Insert("response_format", response_format);
			};

			if(speed >= 0.25 & speed <= 4.0) {
				audio_json->Insert("speed", speed);
			}
			else {
				audio_json->Insert("speed", 1.0);
			};
			data := audio_json->ToString()->ToByteArray();
			# data->ToString()->PrintLine();

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/audio/speech"), data, "application/json", headers);
			# response->GetContent()->ToString()->PrintLine();		

			if(response->GetType()->Equals("application/json")) {
				audio_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(audio_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};
				
				if(audio_json->Has("error")) {
					error_str := audio_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};
			};
			
			return Pair->New(response->GetType(), ByteArrayRef->New(response->GetContent()))<String, ByteArrayRef>;
		}
	}
}

#~
Support for OpenAI chat APIs
~#
bundle API.OpenAI.Chat {
	#~
	Model response for a given chat conversation
	~#
	class Completion from EndPoint {
		@id : String;
		@object : String;
		@created_at : Int;
		@model : String;
		@choices : Vector<API.OpenAI.Chat.Choice>;

		New(chat_json : JsonElement) {
			Parent();

			@id := chat_json->Get("id")->GetString();
			@object := chat_json->Get("object")->GetString();
			@created_at := chat_json->Get("created")->GetInt();
			@model := chat_json->Get("model")->GetString();

			@choices := Vector->New()<API.OpenAI.Chat.Choice>;
			choices_json := chat_json->Get("choices");
			each(choice_json in choices_json) {
				@choices->AddBack(Choice->New(choice_json));
			};
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		ID of the model to use
		@return ID of the model to use
		~#
		method : public : GetModel() ~ String {
			return @model;
		}

		#~
		List of chat completion choices
		@return completion choices
		~#
		method : public : GetChoices() ~ Vector<API.OpenAI.Chat.Choice> {
			return @choices;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {			
			buffer := "[id='";
			buffer += @id;

			buffer += "', object='"
			buffer += @object;

			buffer += "', model='"
			buffer += @model;

			buffer += "', created_at="
			buffer += @created_at;

			buffer += "\nchoices: ["
			for(i := 0; i < @choices->Size(); i +=1 ;) {
				buffer += i;
				buffer += ": ";
				
				buffer += @choices->Get(i)->ToString();
				
				if(i + 1 < @choices->Size()) {
					buffer += ',';
				};
			};
			buffer += ']';

			return buffer;
		}

		#~
		Model response for the given chat conversation
		@param messages list of messages comprising the conversation so far.
		@param model ID of the model to use
		@param token API token
		@return completion response
		~#
		function : Complete(model : String, messages : Vector<Pair<String, String>>, token : String) ~ Completion {
			completion_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			completion_json->Insert("model", model);

			messages_json := JsonElement->New(JsonElement->JsonType->ARRAY);
			each(message in messages) {
				message_json := JsonElement->New(JsonElement->JsonType->OBJECT);
				message_json->Insert("role", message->GetFirst());
				message_json->Insert("content", message->GetSecond());
				messages_json->Add(message_json);
			};
			completion_json->Insert("messages", messages_json);

			data := completion_json->ToString()->ToByteArray();
			# data->ToString()->PrintLine();			

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/chat/completions"), data, "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				chat_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(chat_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};
				
				if(chat_json->Has("error")) {
					error_str := chat_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return Completion->New(chat_json);
			};

			return Nil;
		}
	}

	#~
	Completion choice
	~#
	class Choice from EndPoint {
		@index : Int;
		@finish_reason : String;
		@message : Pair<String, String>;

		New(chat_json : JsonElement) {
			Parent();
			@index := chat_json->Get("index")->GetInt();
			@finish_reason := chat_json->Get("finish_reason")->GetString();
			message_json := chat_json->Get("message");

			role := message_json->Get("role")->GetString();
			content := message_json->Get("content")->GetString();
			@message := Pair->New(role, content)<String, String>;
		}

		#~
		Get index
		@return index
		~#
		method : public : GetIndex() ~ Int {
			return @index;
		}

		#~
		Get finish reason
		@return finish reason
		~#
		method : public : GetFinishReason() ~ String {
			return @finish_reason;
		}

		#~
		Get message
		@return message
		~#
		method : public : GetMessage() ~ Pair<String, String> {
			return @message;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			role := @message->GetFirst();
			content := @message->GetSecond();
			return "[index={$@index}, finish_reason='{$@finish_reason}', role={$role}, content={$content}]"; 
		}
	}
}

#~
Support for OpenAIs assistant and general APIs
~#
bundle API.OpenAI {
	class File from EndPoint {
		@id : String;
		@object : String;
		@created_at : Int;
		@bytes : Int;
		@filename : String;
		@purpose : String;
		
		New(file_json : JsonElement, token : String) {
			Parent();

			@id := file_json->Get("id")->GetString();
			@object := file_json->Get("object")->GetString();
			@bytes := file_json->Get("bytes")->GetInt();
			@created_at := file_json->Get("created_at")->GetInt();
			@filename := file_json->Get("filename")->GetString();
			@purpose := file_json->Get("purpose")->GetString();
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Get the size of the file
		@return size of the file
		~#
		method : public : GetBytes() ~ Int {
			return @bytes;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		Get the name of the file
		@return name of the file
		~#
		method : public : GetFilename() ~ String {
			return @filename;
		}

		#~
		Get the purpose
		@return purpose
		~#
		method : public : GetPurpose() ~ String {
			return @purpose;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			return "[id='{$@id}', object='{$@object}', bytes={$@bytes}, created_at={$@created_at}, filename='{$@filename}', purpose='{$@purpose}']"; 
		}

		#~
		Upload a file that can be used across various endpoints
		@param name file object name
		@param content file content
		@param token API token
		@return string representation
		~#
		function : Create(name : String, content : Byte[], token : String) ~ Bool {
			purpose_headers := Map->New()<String, String>;
			purpose_headers->Insert("Content-Disposition", "form-data; name=\"purpose\"");
			purpose_content := Web.HTTP.Server.MultipartContent->New(purpose_headers, "assistants"->ToByteArray());

			content_headers := Map->New()<String, String>;
			content_headers->Insert("Content-Disposition", "form-data; name=\"file\"; filename=\"{$name}\"");
			content_headers->Insert("Content-Type", "application/octet-stream");
			multi_content := Web.HTTP.Server.MultipartContent->New(content_headers, content);

			encoder := Web.HTTP.Server.MultipartEncoder->New();
			encoder->Add(purpose_content);
			encoder->Add(multi_content);
			boundry := encoder->GetBoundary();
			data := encoder->ToByteArray();

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/files"), data, 
				"multipart/form-data; boundary={$boundry}", headers);

			return response->GetCode() = 200;
		}

		#~
		Loads a file
		@param id file ID
		@param token API token
		@return file reference
		~#
		function : Load(id : String, token : String) ~ API.OpenAI.File {
			file : API.OpenAI.File;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickGet(Url->New("https://api.openai.com/v1/files/{$id}"), "application/json", headers);
			
			if(response <> Nil) {
				file_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(file_json = Nil) {
					return Nil;
				};

				if(file_json->Has("error")) {
					error_str := file_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				}

				file := API.OpenAI.File->New(file_json, token);
			};

			return file;
		}

		#~
		Deletes a file
		@param id file ID
		@param token API token
		@return true if successful, false otherwise
		~#
		function : Delete(id : String, token : String) ~ Bool {
			file : API.OpenAI.File;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickDelete(Url->New("https://api.openai.com/v1/files/{$id}"), "application/json", headers);
			
			if(response <> Nil) {
				file_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(file_json = Nil) {
					return false;
				};

				if(file_json->Has("error")) {
					error_str := file_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				}

				return file_json->Get("deleted")->GetString()->Equals("true");
			};

			return false;
		}
		
		#~
		Loads or creates an OpenAI file from the local filesystem
		@param filename local file path
		@param token API token
		@return file reference
		~#
		function : LoadOrCreate(filename : String, token : String) ~ API.OpenAI.File {
			file := LoadByName(filename, token);
			
			if(file = Nil) {
				# "Uploading file: '{$filename}'"->PrintLine();
				content := FileReader->ReadBinaryFile(filename);
				if(content = Nil | content->Size() = 0) {
					"### Error: Unable to load file: '{$filename}' ###"->PrintLine();
					Runtime->Exit(1);
				};

				if(API.OpenAI.File->Create(filename, content, token)) {
					file := LoadByName(filename, token);
				};
			};

			return file;
		}

		#~
		Loads an OpenAI file from the local filesystem
		@param filename local file path
		@param token API token
		@return file reference
		~#
		function : LoadByName(filename : String, token : String) ~ API.OpenAI.File {
			found : API.OpenAI.File;
			
			files := API.OpenAI.File->ListFiles(token);
			each(file in files) {
				decoded_filename := JsonElement->Decode(file->GetFilename());
				if(decoded_filename->Equals(filename)) {
					found := file;
					break;
				};
			};

			return found;
		}

		#~
		Loads a list available OpenAI files
		@param token API token
		@return file reference
		~#
		function : ListFiles(token : String) ~ Vector<API.OpenAI.File> {
			files := Vector->New()<API.OpenAI.File>

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickGet(Url->New("https://api.openai.com/v1/files"), "application/json", headers);
			if(response <> Nil) {
				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				if(root_json->Has("error")) {
					error_str := root_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				files_json := root_json->Get("data");
				each(file_json in files_json) {
					files->AddBack(API.OpenAI.File->New(file_json, token));
				};
			};

			return files;
		}

		#~
		Returns the contents of the specified file
		@param id file ID
		@param token API token
		@return file content
		~#
		function : Retrieve(id : String, token : String) ~ Byte[] {
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			return HttpsClient->QuickGet(Url->New("https://api.openai.com/v1/files/{$id}/content"), "application/json", headers)->GetContent();
		}
	}

	#~
	Builds assistants that can call models and use tools to perform tasks
	~#
	class Assistant from EndPoint {
		@id : String;
		@object : String;
		@model : String;
		@name : String;
		@description : String;
		@instructions : String;
		@created_at : Int;

		@tools : Vector<String>;
		@files : Vector<API.OpenAI.File>;
		@token : String;

		New : private(assistant_json : JsonElement, token : String) {
			Parent();

			@id := assistant_json->Get("id")->GetString();
			@created_at := assistant_json->Get("created_at")->GetInt();
			@object := assistant_json->Get("object")->GetString();
			@name := assistant_json->Get("name")->GetString();
			@description := assistant_json->Get("description")->GetString();
			@model := assistant_json->Get("model")->GetString();
			@instructions := assistant_json->Get("instructions")->GetString();
			@token := token;

			@tools := Vector->New()<String>;
			tools := assistant_json->Get("tools");
			each(tool in tools) {
				tool_desc := tool->Get("type")->GetString();
				@tools->AddBack(tool_desc);
			};

			@files := Vector->New()<API.OpenAI.File>;
			file_ids := assistant_json->Get("file_ids");
			each(file_id in file_ids) {
				file := API.OpenAI.File->Load(file_id->GetString(), token);
				if(file <> Nil) {
					@files->AddBack(file);
				};
			};
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		ID of the model to use
		@return ID of the model to use
		~#
		method : public : GetModel() ~ String {
			return @model;
		}

		#~
		Name of the assistant
		@return name of the assistant
		~#
		method : public : GetName() ~ String {
			return @name;
		}

		#~
		Description of the assistant
		@return description of the assistant
		~#
		method : public : GetDescription() ~ String {
			return @description;
		}

		#~
		System instructions that the assistant uses
		@return system instructions
		~#
		method : public : GetInstructions() ~ String {
			return @instructions;
		}

		#~
		Adds a file to assistant
		@param file file to add to assistant
		@return true if successful, false otherwise
		~#
		method : public : AddFile(file : API.OpenAI.File) ~ Bool {
			file_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			file_json->Insert("file_id", file->GetId());
			data := file_json->ToString()->ToByteArray();

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer sk-{$@token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/assistants/{$@id}/files"), data, "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				file_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(file_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return false;
				};
				
				if(file_json->Has("error")) {
					error_str := file_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				};

				return file->GetId()->Equals(file_json->Get("id")->GetString());
			}

			return false;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {			
			buffer := "[id='";
			buffer += @id;

			buffer += "', object='"
			buffer += @object;

			buffer += "', model='"
			buffer += @model;

			buffer += "', name='"
			buffer += @name;

			buffer += "', description='"
			buffer += @description;

			buffer += "', instructions='"
			buffer += @instructions;

			buffer += "', created_at="
			buffer += @created_at;

			buffer += "\ntools: ["
			for(i := 0; i < @tools->Size(); i +=1 ;) {
				buffer += i;
				buffer += ": ";
				buffer += @tools->Get(i);
				buffer += '\'';
				
				if(i + 1 < @tools->Size()) {
					buffer += ',';
				};
			};

			buffer += "]\nfiles: [";
			for(i := 0; i < @files->Size(); i +=1 ;) {
				buffer += i;
				buffer += ": ";
				buffer += @files->Get(i)->ToString();
								
				if(i + 1 < @files->Size()) {
					buffer += "\n\t";
				};
			};
			buffer += ']';

			return buffer;
		}

		#~
		Returns a list of assistants
		@param token API token
		@return list of assistants
		~#
		function : ListAssistants(token : String) ~ Vector<API.OpenAI.Assistant> {
			assistants := Vector->New()<API.OpenAI.Assistant>

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickGet(Url->New("https://api.openai.com/v1/assistants"), "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				assistants_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(assistants_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};
				
				if(assistants_json->Has("error")) {
					error_str := assistants_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				assistants_json := assistants_json->Get("data");
				each(assistant_json in assistants_json) {
					assistants->AddBack(API.OpenAI.Assistant->New(assistant_json, token));
				};
			};

			return assistants;
		}

		#~
		Create an assistant with a model and instructions
		@param model ID of the model to use
		@param token API token
		@return assistant
		~#
		function : Create(model : String, token : String) ~ API.OpenAI.Assistant {
			return Create(model, Nil, Nil, Nil, Nil, Nil, token);
		}

		#~
		Create an assistant with a model and instructions
		@param model ID of the model to use
		@param name name to use
		@param description description of the assistant.
		@param instructions the system instructions that the assistant uses
		@param token API token
		@return newly created assistant
		~#
		function : Create(model : String, name : String, description : String, instructions : String, token : String) ~ API.OpenAI.Assistant {
			return Create(model, name, description, instructions, Nil, Nil, token);
		}

		#~
		Creates an assistant with a model and instructions
		@param model ID of the model to use
		@param name name to use
		@param description description of the assistant.
		@param instructions the system instructions that the assistant uses
		@param tools list of tool enabled on the assistant
		@param files list of file IDs attached to this assistant
		@param token API token
		@return newly created assistant
		~#
		function : Create(model : String, name : String, description : String, instructions : String, 
				tools : Vector<String>, files : Vector<API.OpenAI.File>, token : String) ~ API.OpenAI.Assistant {
			if(model = Nil) {
				return Nil;
			};

			@token : String;

			builder := JsonBuilder->New();
			create_json := builder->PushObject();
			create_json->Insert("model", model);

			if(name <> Nil) {
				create_json->Insert("name", name);
			};

			if(description <> Nil) {
				create_json->Insert("description", description);
			};

			if(instructions <> Nil) {
				create_json->Insert("instructions", instructions);
			};

			# tools
			if(<>tools->IsEmpty()) {
				tools_json := JsonElement->New(JsonElement->JsonType->ARRAY);
				each(tool in tools) {
					tool_json := JsonElement->New(JsonElement->JsonType->OBJECT);
					tool_json->Insert("type", tool);
					tools_json->Add(tool_json);
				};
				create_json->Insert("tools", tools_json);
			};

			# files
			if(<>files->IsEmpty()) {
				files_json := JsonElement->New(JsonElement->JsonType->ARRAY);
				each(file in files) {
					files_json->Add(file->GetId());
				};
				create_json->Insert("file_ids", files_json);
			};
			
			data := builder->PopAll()->ToString()->ToByteArray();
			# data->ToString()->PrintLine();			

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/assistants"), data, "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString();				
				assistant_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(assistant_json = Nil) {
					return Nil;
				};
				
				if(assistant_json->Has("error")) {
					error_str := assistant_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				}

				return API.OpenAI.Assistant->New(assistant_json, token);
			};

			return Nil;
		}

		#~
		Loads an assistant with a model and instructions
		@param id model ID of the model to use
		@param token API token
		@return loaded assistant
		~#
		function : Load(id : String, token : String) ~ API.OpenAI.Assistant {
			assistant : API.OpenAI.Assistant;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickGet(Url->New("https://api.openai.com/v1/assistants/{$id}"), "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				assistant_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(assistant_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};
				
				if(assistant_json->Has("error")) {
					error_str := assistant_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				assistant := API.OpenAI.Assistant->New(assistant_json, token);
			};

			return assistant;
		}

		#~
		Deletes an assistant with a model and instructions
		@param id model ID of the model to use
		@param token API token
		@return true if successful, false otherwise
		~#
		function : Delete(id : String, token : String) ~ Bool {
			file : API.OpenAI.File;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickDelete(Url->New("https://api.openai.com/v1/assistants/{$id}"), "application/json", headers);
			
			if(response <> Nil) {
				file_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(file_json = Nil) {
					return false;
				};

				if(file_json->Has("error")) {
					error_str := file_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				}

				return file_json->Get("deleted")->GetString()->Equals("true");
			};

			return false;
		}
	}

	#~
	Create threads that assistants can interact with
	~#
	class Thread from EndPoint {
		@id : String;
		@object : String;
		@created_at : Int;

		New : private(thread_json : JsonElement) {
			Parent();

			@id := thread_json->Get("id")->GetString();
			@created_at := thread_json->Get("created_at")->GetInt();
			@object := thread_json->Get("object")->GetString();
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			buffer := "[id='";
			buffer += @id;

			buffer += "', object='"
			buffer += @object;

			buffer += "', created_at="
			buffer += @created_at;

			buffer += "]";

			return buffer;
		}

		#~
		Creates a thread
		@param token API token
		@return newly created thread
		~#
		function : Create(token : String) ~ API.OpenAI.Thread {
			thread : API.OpenAI.Thread;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/threads"), ""->ToByteArray(), "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				thread_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(thread_json = Nil) {
					"### Error: Unable to parse thread response ###"->ErrorLine();
					return Nil;
				};
				
				if(thread_json->Has("error")) {
					error_str := thread_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return API.OpenAI.Thread->New(thread_json);
			};
			
			return Nil;	
		}

		#~
		Loads an existing thread
		@param id ID of the model to use
		@param token API token
		@return loaded thread
		~#
		function : Load(id : String, token : String) ~ API.OpenAI.Thread {
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickGet(Url->New("https://api.openai.com/v1/threads/{$id}"), "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				thread_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(thread_json = Nil) {
					"### Error: Unable to parse thread response ###"->ErrorLine();
					return Nil;
				};
				
				if(thread_json->Has("error")) {
					error_str := thread_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return API.OpenAI.Thread->New(thread_json);

			};

			return Nil;
		}

		#~
		Loads an existing thread
		@param id ID of the model to use
		@param token API token
		@return loaded thread
		~#
		function : Delete(id : String, token : String) ~ Bool {
			thread : API.OpenAI.Thread;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickDelete(Url->New("https://api.openai.com/v1/threads/{$id}"), "application/json", headers);
			
			if(response <> Nil) {
				thread_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(thread_json = Nil) {
					return false;
				};

				if(thread_json->Has("error")) {
					error_str := thread_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				}

				return thread_json->Get("deleted")->GetString()->Equals("true");
			};

			return false;
		}
	}

	#~
	Create messages within threads
	~#
	class Message from EndPoint {
		@id : String;
		@object : String;
		@created_at : Int;
		
		@thread_id : String;
		@role : String;
		@contents : Vector<Pair<String, String>>;
		@files : Vector<API.OpenAI.File>;

		New : private(message_json : JsonElement, token : String) {
			Parent();

			@id := message_json->Get("id")->GetString();
			@created_at := message_json->Get("created_at")->GetInt();
			@object := message_json->Get("object")->GetString();
			@thread_id := message_json->Get("thread_id")->GetString();
			@role := message_json->Get("role")->GetString();

			@contents := Vector->New()<Pair<String, String>>;	
			contents_json := message_json->Get("content");
			each(content_json in contents_json) {
				type := content_json->Get("type")->GetString();
				value := content_json->Get("text")->Get("value")->GetString();
				@contents->AddBack(Pair->New(type, value)<String, String>);
			};

			@files := Vector->New()<API.OpenAI.File>;
			file_ids := message_json->Get("file_ids");
			each(file_id in file_ids) {
				file := API.OpenAI.File->Load(file_id->GetString(), token);
				if(file <> Nil) {
					@files->AddBack(file);
				};
			};
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		Get the ID of the thread associated with message
		@return thread ID
		~#
		method : public : GetThreadId() ~ String {
			return @thread_id;
		}

		#~
		Get the role of the entity that is creating the message
		@return role of the entity that is creating the message
		~#
		method : public : GetRole() ~ String {
			return @role;
		}

		#~
		Get the content of the message
		@return list of messages with roles
		~#
		method : public : GetContents() ~ Vector<Pair<String, String>> {
			return @contents;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			buffer := "[id='";
			buffer += @id;

			buffer += "', object='"
			buffer += @object;

			buffer += "', created_at="
			buffer += @created_at;

			buffer += ", role='"
			buffer += @role;

			buffer += "''\ncontents: [";
			for(i := 0; i < @contents->Size(); i +=1 ;) {
				buffer += '{';
				buffer += i;
				buffer += ": type=";

				content := @contents->Get(i);
				buffer += content->GetFirst();
				buffer += ", text=\"";
				buffer += content->GetSecond();
				buffer += "\"}";
												
				if(i + 1 < @contents->Size()) {
					buffer += "\n\t";
				};
			};
			buffer += ']';

			return buffer;
		}

		#~
		Loads a message
		@param role role of the entity that is creating the message
		@param content content of the message.
		@param thread thread associated with message
		@param token API token
		@return loaded Message
		~#
		function : Create(role : String, content : String, thread : API.OpenAI.Thread, token : String) ~ API.OpenAI.Message {
			return Create(role, content , thread, Nil, token);
		}

		#~
		Create a message.
		@param role role of the entity that is creating the message
		@param content content of the message.
		@param thread thread associated with message
		@param files list to attach to the message
		@param token API token
		@return newly created message
		~#
		function : Create(role : String, content : String, thread : API.OpenAI.Thread, files : Vector<API.OpenAI.File>, token : String) ~ API.OpenAI.Message {
			message_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			message_json->Insert("role", role);
			message_json->Insert("content", content);

			# files
			if(<>files->IsEmpty()) {
				files_json := JsonElement->New(JsonElement->JsonType->ARRAY);
				each(file in files) {
					files_json->Add(file->GetId());
				};
				message_json->Insert("file_ids", files_json);
			};

			data := message_json->ToString()->ToByteArray();
			
			thread_id := thread->GetId();
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/threads/{$thread_id}/messages"), data, "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				message_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(message_json = Nil) {
					"### Error: Unable to parse thread response ###"->ErrorLine();
					return Nil;
				};
				
				if(message_json->Has("error")) {
					error_str := message_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return API.OpenAI.Message->New(message_json, token);
			};
			
			return Nil;	
		}

		#~
		Loads a message
		@param id message ID
		@param thread thread associated with message
		@param token API token
		@return loaded Message
		~#
		function : Load(id : String, thread : API.OpenAI.Thread, token : String) ~ API.OpenAI.Message {
			thread_id := thread->GetId();
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickGet(Url->New("https://api.openai.com/v1/threads/{$thread_id}/messages/{$id}"), "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				if(root_json->Has("error")) {
					error_str := root_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				if(root_json->Has("error")) {
					error_str := root_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return API.OpenAI.Message->New(root_json, token);
			}

			return Nil;
		}

		#~
		Loads a messages associated with thread
		@param thread thread associated with message
		@param token API token
		@return messages associated with thread
		~#
		function : ListMessages(thread : API.OpenAI.Thread, token : String) ~ Vector<API.OpenAI.Message> {
			messages := Vector->New()<API.OpenAI.Message>

			thread_id := thread->GetId();
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickGet(Url->New("https://api.openai.com/v1/threads/{$thread_id}/messages"), "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				if(root_json->Has("error")) {
					error_str := root_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				messages_json := root_json->Get("data");
				each(message_json in messages_json) {
					messages->AddBack(API.OpenAI.Message->New(message_json, token));
				};
			};

			return messages;
		}
	}

	#~
	Represents an execution run on a thread
	~#
	class Run from EndPoint {
		@id : String;
		@object : String;
		@created_at : Int;
		@thread_id : String;
		@assistant_id : String;
		@status : String;

		New : private(run_json : JsonElement) {
			Parent();
			Set(run_json);
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		The status of the run, which can be either: 'queued', 'in_progress', 
		'requires_action', 'cancelling', 'cancelled', 'failed', 'completed', or 'expired'.
		~#
		method : public : GetStatus() ~ String {
			return @status;
		}
		
		method: Set(run_json : JsonElement) ~ Nil {
			@id := run_json->Get("id")->GetString();
			@created_at := run_json->Get("created_at")->GetInt();
			@object := run_json->Get("object")->GetString();
			@thread_id := run_json->Get("thread_id")->GetString();
			@assistant_id := run_json->Get("assistant_id")->GetString();
			@status := run_json->Get("status")->GetString();
		}

		#~
		Create a run
		@param assistant the assistant to use to execute this run
		@param thread thread to run
		@param token API token
		@return newly created Run
		~#
		function : Create(assistant : API.OpenAI.Assistant, thread : API.OpenAI.Thread, token : String) ~ API.OpenAI.Run {
			run_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			run_json->Insert("assistant_id", assistant->GetId());
			data := run_json->ToString()->ToByteArray();
			
			thread_id := thread->GetId();
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/threads/{$thread_id}/runs"), data, "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				run_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(run_json = Nil) {
					"### Error: Unable to parse thread response ###"->ErrorLine();
					return Nil;
				};
				
				if(run_json->Has("error")) {
					error_str := run_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return API.OpenAI.Run->New(run_json);
			};
			
			return Nil;	
		}

		#~
		Refreshed the run's data such as status
		@param token API token
		@return newly created Run
		~#
		method : public : Refresh(token : String) ~ Bool {
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickGet(Url->New("https://api.openai.com/v1/threads/{$@thread_id}/runs/{$@id}"), "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				run_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(run_json = Nil) {
					return false;
				};

				if(run_json->Has("error")) {
					error_str := run_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				};

				run_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(run_json = Nil) {
					return false;
				};

				if(run_json->Has("error")) {
					error_str := run_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				};

				Set(run_json);				
				return true;
			}

			return false;
		}

		#~
		Loads a run
		@param id run ID
		@param thread instance associated with run
		@param token API token
		@return loaded Run
		~#
		function : Load(id : String, thread : API.OpenAI.Thread, token : String) ~ API.OpenAI.Run {
			thread_id := thread->GetId();
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickGet(Url->New("https://api.openai.com/v1/threads/{$thread_id}/runs/{$id}"), "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				if(root_json->Has("error")) {
					error_str := root_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				if(root_json->Has("error")) {
					error_str := root_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return API.OpenAI.Run->New(root_json);
			}

			return Nil;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			buffer := "[id='";
			buffer += @id;

			buffer += "', object='"
			buffer += @object;

			buffer += "', created_at='"
			buffer += @created_at;

			buffer += "', created_at="
			buffer += @created_at;

			buffer += ", assistant_id='"
			buffer += @assistant_id;

			buffer += "', thread_id='"
			buffer += @thread_id;

			buffer += "', status='"
			buffer += @status;

			buffer += "']";

			return buffer;
		}
	}

	#~
	OpenAI endpoint
	~#
	class EndPoint {
		@last_message : static : String;

		function : SetLastError(last_message : String) ~ Nil {
			@last_message := last_message;

		}

		#~
		Get the last error
		@return last error
		~#
		function : GetLastError() ~ String {
			return @last_message;
		}
	}
}
