use Collection;
use System.Matrix;

class NeuralNetwork {
	@input_nodes : Float;
	@hidden_nodes : Float;
	@output_nodes : Float;
	@learning_rate : Float;
	@weight_inputs_hidden : Float[,];
	@weight_outputs_hidden : Float[,];

	function : Main(args : String[]) ~ Nil {
		Brun(2, 32, 1, 0.0125, 50000);
	}

	function : native : Brun(input_nodes : Int, hidden_nodes : Int, output_nodes : Int, learning_rate : Float, iterations : Int) ~ Nil {
		network := NeuralNetwork->New(input_nodes, hidden_nodes, output_nodes, learning_rate);

		# train data weight and height, true female
		inputs := Vector->New()<MatrixRef>;
		targets := Vector->New()<MatrixRef>;
		inputs->AddBack(MatrixRef->New([[115.0][66.0]]));
		targets->AddBack(MatrixRef->New([[1.0]]));

		inputs->AddBack(MatrixRef->New([[175.0], [78.0]]));
		targets->AddBack(MatrixRef->New([[0.0]]));

		inputs->AddBack(MatrixRef->New([[205.0], [72.0]]));
		targets->AddBack(MatrixRef->New([[0.0]]));

		inputs->AddBack(MatrixRef->New([[120.0], [67.0]]));
		targets->AddBack(MatrixRef->New([[1.0]]));

		inputs->AddBack(MatrixRef->New([[100.0], [58.0]]));
		targets->AddBack(MatrixRef->New([[1.0]]));

		inputs->AddBack(MatrixRef->New([[95.0], [75.0]]));
		targets->AddBack(MatrixRef->New([[1.0]]));

		inputs->AddBack(MatrixRef->New([[225.0], [73.0]]));
		targets->AddBack(MatrixRef->New([[0.0]]));

		network->Train(inputs, targets, learning_rate, iterations);

		# test
		network->Query(MatrixRef->New([[167.0], [73.0]]))->PrintLine();
		network->Query(MatrixRef->New([[105.0], [67.0]]))->PrintLine();
		network->Query(MatrixRef->New([[120.0], [72.0]]))->PrintLine();
		network->Query(MatrixRef->New([[143.0], [68.0]]))->PrintLine();
		network->Query(MatrixRef->New([[115.0], [58.0]]))->PrintLine();
		network->Query(MatrixRef->New([[205.0], [82.0]]))->PrintLine();
		network->Query(MatrixRef->New([[95.0], [55.0]]))->PrintLine();
	}
	
	New(input_nodes : Float, hidden_nodes : Float, output_nodes : Float, learning_rate : Float) {
		@input_nodes := input_nodes;
		@hidden_nodes := hidden_nodes;
		@output_nodes := output_nodes;
		@learning_rate := learning_rate;

		@weight_inputs_hidden := Matrix2D->RandomNormal(0.0, Float->Pow(@input_nodes, -1.0), @hidden_nodes, @input_nodes);
		@weight_outputs_hidden := Matrix2D->RandomNormal(0.0, Float->Pow(@input_nodes, -1.0), @output_nodes, @hidden_nodes);
	}

	method : public : Query(inputs : MatrixRef) ~ Bool {
		# try 10x and fail
		values :=  inputs->Get();
		each(i : 10) {
			outputs := Query(values);

			if(outputs[0,0] > 0.85) {
				return true;
			}
			else if(outputs[0,0] < 0.15) {
				return false;
			}
		};

		return false;
	}

	method : Query(inputs : Float[,]) ~ Float[,] {
		# calculate signals into hidden layer
		hidden_outputs := Matrix2D->DotSigmoid(@weight_inputs_hidden, inputs);
		# calculate the signals emerging from final output layer
		return Matrix2D->DotSigmoid(@weight_outputs_hidden, hidden_outputs);
	}

	method : public : Train(inputs : Vector<MatrixRef>, targets : Vector<MatrixRef>, rate : Float, iterations : Int) ~ Nil {
		if(inputs->Size() = targets->Size()) {
			each(i : iterations) {
				each(j : inputs) {
					input := inputs->Get(j)->Get();
					target := targets->Get(j)->Get();

					# calculate signals into hidden layer
					hidden_outputs := Matrix2D->DotSigmoid(@weight_inputs_hidden, input);
					# calculate signals into final output layer
					final_outputs  := Matrix2D->DotSigmoid(@weight_outputs_hidden, hidden_outputs);
					# output layer error is the (target - actual)
					output_errors := Matrix2D->Subtract(target, final_outputs);
					# hidden layer error is the output_errors, split by weights, recombined at hidden nodes
					hidden_errors := Matrix2D->Dot(Matrix2D->Transpose(@weight_outputs_hidden), output_errors);
					# update the weights for the links between the input and hidden layers
					@weight_inputs_hidden := Matrix2D->Add(@weight_inputs_hidden, Adjust(rate, hidden_errors, hidden_outputs, input));
					# update the weights for the links between the hidden and output layers
					@weight_outputs_hidden := Matrix2D->Add(@weight_outputs_hidden, Adjust(rate, output_errors, final_outputs, hidden_outputs));
				};
			};
		};
	}

	method : Adjust(rate : Float, errors : Float[,], outputs : Float[,], inputs : Float[,]) ~ Float[,] {
		return Matrix2D->Multiple(rate, Matrix2D->Dot(Matrix2D->Multiple(errors, Matrix2D->Multiple(outputs, Matrix2D->Subtract(1.0, outputs))), Matrix2D->Transpose(inputs)));
	}
}